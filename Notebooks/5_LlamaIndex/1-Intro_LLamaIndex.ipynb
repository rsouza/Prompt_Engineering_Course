{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c058a22-bd74-490d-a9e3-df2e2de7d144",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Quick intro to LlamaIndex  \n",
    "Sources: [1](https://lmy.medium.com/comparing-langchain-and-llamaindex-with-4-tasks-2970140edf33), [2](https://docs.llamaindex.ai/en/stable/), [3](https://github.com/run-llama/llama_index), [4](https://nanonets.com/blog/llamaindex/)  \n",
    "\n",
    "LlamaIndex is a \"data framework\" to help you build LLM apps. It provides the following tools:\n",
    "\n",
    "+ Offers data connectors to ingest your existing data sources and data formats (APIs, PDFs, docs, SQL, etc.).\n",
    "+ Provides ways to structure your data (indices, graphs) so that this data can be easily used with LLMs.\n",
    "+ Provides an advanced retrieval/query interface over your data: Feed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\n",
    "+ Allows easy integrations with your outer application framework (e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\n",
    "+ LlamaIndex provides tools for both beginner users and advanced users.  \n",
    "\n",
    "The high-level API allows beginner users to use LlamaIndex to ingest and query their data in 5 lines of code.  \n",
    "The lower-level APIs allow advanced users to customize and extend any module (data connectors, indices, retrievers, query engines, reranking modules), to fit their needs.  \n",
    "\n",
    "LlamaIndex provides the following tools:\n",
    "+ Data connectors ingest your existing data from their native source and format. These could be APIs, PDFs, SQL, and (much) more.\n",
    "+ Data indexes structure your data in intermediate representations that are easy and performant for LLMs to consume.\n",
    "+ Engines provide natural language access to your data. For example:\n",
    "+ Query engines are powerful retrieval interfaces for knowledge-augmented output.\n",
    "+ Chat engines are conversational interfaces for multi-message, “back and forth” interactions with your data.\n",
    "+ Data agents are LLM-powered knowledge workers augmented by tools, from simple helper functions to API integrations and more.\n",
    "+ Application integrations tie LlamaIndex back into the rest of your ecosystem. This could be LangChain, Flask, Docker, ChatGPT, or… anything else!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7f6931d-f17f-4b44-ad98-209eff067812",
     "showTitle": false,
     "title": "ro"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/simple/\nCollecting llama-index[local_models]\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/53/c6/dd12ba91d4a8671d84a40f2469132219cf1dedb7a3da7a73583b0335cc27/llama_index-0.9.46-py3-none-any.whl (15.9 MB)\nWARNING: llama-index 0.9.46 does not provide the extra 'local_models'\nRequirement already satisfied: dataclasses-json in /databricks/python3/lib/python3.10/site-packages (from llama-index[local_models]) (0.6.3)\nCollecting typing-extensions>=4.5.0\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl (32 kB)\nCollecting networkx>=3.0\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/d5/f0/8fbc882ca80cf077f1b246c0e3c3465f7f415439bdea6b899f6b19f61f70/networkx-3.2.1-py3-none-any.whl (1.6 MB)\nCollecting nltk<4.0.0,>=3.8.1\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5 MB)\nRequirement already satisfied: typing-inspect>=0.8.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index[local_models]) (0.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index[local_models]) (2023.6.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from llama-index[local_models]) (1.5.3)\nCollecting nest-asyncio<2.0.0,>=1.5.8\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/a0/c4/c2971a3ba4c6103a3d10c4b0f24f461ddc027f0f09763220cf35ca1401b3/nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\nCollecting SQLAlchemy[asyncio]>=1.4.49\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/2c/e6/967cd898cbce485c385d4cd644195f906b2571f9393dc1537019a821a8a6/SQLAlchemy-2.0.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\nCollecting requests>=2.31.0\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl (62 kB)\nCollecting httpx\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl (75 kB)\nCollecting deprecated>=1.2.9.3\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\nRequirement already satisfied: tiktoken>=0.3.3 in /databricks/python3/lib/python3.10/site-packages (from llama-index[local_models]) (0.5.2)\nCollecting tenacity<9.0.0,>=8.2.0\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl (24 kB)\nCollecting dirtyjson<2.0.0,>=1.0.8\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/68/69/1bcf70f81de1b4a9f21b3a62ec0c83bdff991c88d6cc2267d02408457e88/dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from llama-index[local_models]) (1.23.5)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /databricks/python3/lib/python3.10/site-packages (from llama-index[local_models]) (3.9.1)\nCollecting openai>=1.1.0\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/26/a1/75474477af2a1dae3a25f80b72bbaf20e8296191ece7fff2f67984206f33/openai-1.12.0-py3-none-any.whl (226 kB)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index[local_models]) (22.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index[local_models]) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index[local_models]) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index[local_models]) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index[local_models]) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index[local_models]) (1.9.4)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index[local_models]) (1.14.1)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index[local_models]) (1.2.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index[local_models]) (4.64.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index[local_models]) (8.0.4)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index[local_models]) (2022.7.9)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from openai>=1.1.0->llama-index[local_models]) (1.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index[local_models]) (1.7.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.10/site-packages (from openai>=1.1.0->llama-index[local_models]) (3.5.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.10/site-packages (from openai>=1.1.0->llama-index[local_models]) (1.10.6)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index[local_models]) (3.4)\nCollecting httpcore==1.*\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl (76 kB)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index[local_models]) (2022.12.7)\nCollecting h11<0.15,>=0.13\n  Using cached https://artifacts.rbi.tech/artifactory/api/pypi/pypi-group/packages/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index[local_models]) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index[local_models]) (2.0.4)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index[local_models]) (2.0.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index[local_models]) (0.4.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json->llama-index[local_models]) (3.20.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->llama-index[local_models]) (2022.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->llama-index[local_models]) (2.8.2)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index[local_models]) (23.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index[local_models]) (1.16.0)\nInstalling collected packages: dirtyjson, typing-extensions, tenacity, requests, nltk, networkx, nest-asyncio, h11, deprecated, SQLAlchemy, httpcore, httpx, openai, llama-index\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9769f94c-b348-470c-bc9a-ce69626c5500\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 8.1.0\n    Not uninstalling tenacity at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9769f94c-b348-470c-bc9a-ce69626c5500\n    Can't uninstall 'tenacity'. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.28.1\n    Not uninstalling requests at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9769f94c-b348-470c-bc9a-ce69626c5500\n    Can't uninstall 'requests'. No files were found to uninstall.\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.7\n    Not uninstalling nltk at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9769f94c-b348-470c-bc9a-ce69626c5500\n    Can't uninstall 'nltk'. No files were found to uninstall.\n  Attempting uninstall: networkx\n    Found existing installation: networkx 2.8.4\n    Not uninstalling networkx at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9769f94c-b348-470c-bc9a-ce69626c5500\n    Can't uninstall 'networkx'. No files were found to uninstall.\n  Attempting uninstall: nest-asyncio\n    Found existing installation: nest-asyncio 1.5.6\n    Not uninstalling nest-asyncio at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9769f94c-b348-470c-bc9a-ce69626c5500\n    Can't uninstall 'nest-asyncio'. No files were found to uninstall.\n  Attempting uninstall: SQLAlchemy\n    Found existing installation: SQLAlchemy 1.4.39\n    Not uninstalling sqlalchemy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9769f94c-b348-470c-bc9a-ce69626c5500\n    Can't uninstall 'SQLAlchemy'. No files were found to uninstall.\n  Attempting uninstall: openai\n    Found existing installation: openai 0.27.0\n    Uninstalling openai-0.27.0:\n      Successfully uninstalled openai-0.27.0\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-engineering 0.2.0 requires pyspark<4,>=3.1.2, which is not installed.\ndatabricks-sdk 0.1.6 requires requests<2.29.0,>=2.28.1, but you have requests 2.31.0 which is incompatible.\nSuccessfully installed SQLAlchemy-2.0.25 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 llama-index-0.9.46 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.8.1 openai-1.12.0 requests-2.31.0 tenacity-8.2.3 typing-extensions-4.9.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai==0.27.0\n",
    "#!pip install -qU llama-index            # Just the core components\n",
    "!pip install llama-index[local_models] # Installs tools useful for private LLMs, local inference, and HuggingFace models\n",
    "#!pip install llama-index[postgres]     # Is useful if you are working with Postgres, PGVector or Supabase\n",
    "#!pip install llama-index[query_tools]  # Gives you tools for hybrid search, structured outputs, and node post-processing\n",
    "# !pip install google-generativeai  #PALM\n",
    "!pip install -qU pypdf\n",
    "!pip install -qU docx2txt\n",
    "!pip install -qU sentence-transformers\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bb3df4f-2bfa-452b-b734-262f7d9abcd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "#import tiktoken\n",
    "#from funcy import lcat, lmap, linvoke\n",
    "#from IPython.display import display, Markdown\n",
    "import openai\n",
    "\n",
    "#OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]  #It has to be defined before importing LlamaIndex modules\n",
    "\n",
    "## LlamaIndex LLMs\n",
    "#from openai import OpenAI\n",
    "#from openai import AzureOpenAI\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.llms import ChatMessage\n",
    "#from llama_index.llms import Ollama\n",
    "#from llama_index.llms import PaLM\n",
    "\n",
    "## LlamaIndex Embeddings\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index.embeddings import AzureOpenAIEmbedding\n",
    "from llama_index.embeddings import resolve_embed_model\n",
    "\n",
    "## Llamaindex readers \n",
    "from llama_index import SimpleDirectoryReader\n",
    "#from llama_index import ResponseSynthesizer\n",
    "\n",
    "## LlamaIndex Index Types\n",
    "#from llama_index import GPTListIndex             \n",
    "from llama_index import VectorStoreIndex\n",
    "#from llama_index import GPTVectorStoreIndex  \n",
    "#from llama_index import GPTTreeIndex\n",
    "#from llama_index import GPTKeywordTableIndex\n",
    "#from llama_index import GPTSimpleKeywordTableIndex\n",
    "#from llama_index import GPTDocumentSummaryIndex\n",
    "#from llama_index import GPTKnowledgeGraphIndex\n",
    "#from llama_index.indices.struct_store import GPTPandasIndex\n",
    "#from llama_index.vector_stores import ChromaVectorStore\n",
    "\n",
    "## LlamaIndex Context Managers\n",
    "from llama_index import ServiceContext\n",
    "from llama_index import StorageContext\n",
    "from llama_index import load_index_from_storage\n",
    "from llama_index import set_global_service_context\n",
    "from llama_index.response_synthesizers import get_response_synthesizer\n",
    "#from llama_index import LLMPredictor\n",
    "\n",
    "## LlamaIndex Callbacks\n",
    "#from llama_index.callbacks import CallbackManager\n",
    "#from llama_index.callbacks import LlamaDebugHandler\n",
    "\n",
    "\n",
    "## Defining LLM Model\n",
    "llm_option = \"OpenAI\"\n",
    "if llm_option == \"OpenAI\":\n",
    "    openai.api_type = \"azure\"\n",
    "    azure_endpoint = \"https://rg-rbi-aa-aitest-dsacademy.openai.azure.com/\"\n",
    "    #azure_endpoint = \"https://chatgpt-summarization.openai.azure.com/\"\n",
    "    openai.api_version = \"2023-07-01-preview\"\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    deployment_name = \"model-gpt-35-turbo\"\n",
    "    openai_model_name = \"gpt-35-turbo\"\n",
    "    llm = AzureOpenAI(api_key=openai.api_key,\n",
    "                      azure_endpoint=azure_endpoint,\n",
    "                      model=openai_model_name,\n",
    "                      engine=deployment_name,\n",
    "                      api_version=openai.api_version,\n",
    "                      )\n",
    "elif llm_option == \"Local\":  #https://docs.llamaindex.ai/en/stable/module_guides/models/llms.html and https://docs.llamaindex.ai/en/stable/module_guides/models/llms/local.html\n",
    "    print(\"Make sure you have installed Local Models - !pip install llama-index[local_models]\")\n",
    "    llm = Ollama(model=\"mistral\", request_timeout=30.0)\n",
    "else:\n",
    "    raise ValueError(\"Invalid LLM Model\")\n",
    "\n",
    "## Defining Embedding Model\n",
    "emb_option = \"Local\"\n",
    "if emb_option == \"OpenAI\":\n",
    "    embed_model_name = \"text-embedding-ada-002\"\n",
    "    embed_model_deployment_name = \"model-text-embedding-ada-002\"\n",
    "    embed_model = AzureOpenAIEmbedding(model=embed_model_name,\n",
    "                                       deployment_name=embed_model_deployment_name,\n",
    "                                       api_key=openai.api_key,\n",
    "                                       azure_endpoint=azure_endpoint)\n",
    "elif emb_option == \"Local\":\n",
    "    embed_model = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")   ## bge-m3 embedding model\n",
    "else:\n",
    "    raise ValueError(\"Invalid Embedding Model\")\n",
    "\n",
    "## Logging Optionals\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ecbe217-c8a5-40eb-8228-6060db6949a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Text Completion Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87ae85fb-32ab-4230-9d6b-5a2d329408da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a computer scientist, entrepreneur, and essayist. He is best known as the co-founder of the startup accelerator Y Combinator, which has helped launch companies such as Dropbox, Airbnb, and Reddit. Graham is also the author of several influential essays on technology, startups, and programming, including \"Hackers and Painters\" and \"The Age of the Essay.\" He has been a vocal advocate for the importance of creativity, curiosity, and independent thinking in the tech industry.\n"
     ]
    }
   ],
   "source": [
    "resp = llm.complete(\"Paul Graham is \")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "001b0c93-3d49-431f-944f-2eadb153a61c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Chat Example Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58062725-56ee-4d14-aea1-293db9f40985",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: My name is Captain Rainbowbeard!\n"
     ]
    }
   ],
   "source": [
    "messages = [ChatMessage(role=\"system\", content=\"You are a pirate with a colorful personality\"),\n",
    "            ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "            ]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a1275f5-48c0-4e4f-acb9-6e0f848af08e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Quickstart: Implementing a RAG Pipeline:\n",
    "\n",
    "![](https://docs.llamaindex.ai/en/stable/_images/basic_rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca614505-2820-4fc3-894f-c6dbfa629999",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Examining Documents Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da840490-f086-4de4-ab76-ffa8abf92a50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pride_Prejudice.txt\nRomeoJuliet.txt\n"
     ]
    }
   ],
   "source": [
    "DOCS_DIR = \"../../Data/txt/\"\n",
    "docs = os.listdir(DOCS_DIR)\n",
    "docs = [d for d in docs] # if d.endswith(\".txt\")]\n",
    "docs.sort()\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1d2f4a2-d2bc-41da-a75d-d51cfb7a68c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Setting the Service Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2856988c-f08a-45d2-adf9-945df50f3fb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "990ef080-353d-41ff-910d-cd1e31a3c4f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39ec9553-2e9e-4f83-a9e1-e33084f93ff7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"/Workspace/ds-academy-research/LLamaIndex_quick/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e82be14-3c9c-410e-a843-de9db7c05ded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Directory /Workspace/ds-academy-research/LLamaIndex_quick/\nLoading Documents...\nCreating Vector Store...\nPersisting Vector Store...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(PERSIST_DIR):\n",
    "    shutil.rmtree(PERSIST_DIR)\n",
    "print(f\"Creating Directory {PERSIST_DIR}\")\n",
    "os.mkdir(PERSIST_DIR)\n",
    "\n",
    "if os.listdir(PERSIST_DIR) == []:\n",
    "    print(\"Loading Documents...\")\n",
    "    documents = SimpleDirectoryReader(DOCS_DIR).load_data()\n",
    "    print(\"Creating Vector Store...\")\n",
    "    index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "    print(\"Persisting Vector Store...\")\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a82211c0-d2bb-43c2-a660-a078e2933481",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Reading from existing Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e1cd3f0-570e-4788-bd0e-29c1efd6a321",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from Vector Store...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading from Vector Store...\")\n",
    "storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08794919-a98f-409c-ba71-14b6e1706f4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'82aab630-1a18-4b16-835b-ab7cb2e41713': RefDocInfo(node_ids=['7eb9022c-8e3d-4632-9753-54726bb5608d', '519ac749-cffc-4c9b-813d-22911f172b30', '349c5c51-ff3d-406d-9d37-5f70e8f65b17', 'e56ea9d0-485d-42e6-bc80-87338fb562ff', '222ae7a1-f066-46c0-aa7f-9177fab2c63a', 'edabf752-ab30-4e6a-804b-7dff5758a46f', 'c93e0f5b-bc66-4c63-b444-0b5d2264a088', 'd5fb2ef5-c58c-4fb1-95e7-fc0a5c13c818', '29b7acd1-0c9f-4b06-92cf-68ad7fb30de5', '14b000ee-da63-4101-add9-7000d55a0301', '8f900362-9cfa-4476-826a-d060240737d8', 'fae69770-5903-49e4-9667-7622b571d48f', '7311f479-18d8-4c73-a9fc-df010b46d4b6', 'd1b9a07a-3a3c-4093-85d5-a466e0bdd74d', 'fd56df33-f021-4ed7-a659-d185c799c925', '4cc44803-1a45-40bb-93a7-5e72fe5ecb94', '6902d789-5202-426e-92c7-40c81c1af8ec', '0d85bcaa-5905-4480-a4a4-72f3fc0ff278', '3af3ddb2-4772-4114-8ce9-3e3078350ad6', 'a065e396-dde9-454f-bd13-5aa5911dee76', 'cd9ba6fc-0a6b-4870-b2c7-2e3e1b167eb1', '493d06c9-84ae-4c26-9848-8b754c2be9ce', 'b6193665-6d10-44c9-95bb-ed65c52c04d2', 'c652906c-6bc3-44e8-b581-18145cf2f465', 'da229a8e-7cd0-4776-b86a-3e49aa4115de', '3ab75792-89e9-4d20-9e6d-c995fb46fb6e', 'fd7995da-3b2d-4787-8628-6f039e77bedc', '8ca5063b-76dd-4b27-9988-9bc1c57edda6', '7688bc47-fe59-45fa-9654-95ac4e7764e9', '3cbb47d4-dcc0-4026-8020-bbd394b03958', 'b4c0b31b-49b8-480d-95cc-4554c638cc0c', 'b55e03a5-2be8-4d33-8efe-c15dd8f260e2', '7a046114-2db0-4a5d-9032-62b7c2fd4c2b', '18a735a5-6821-4f25-984d-bc2ce5f2aeea', 'e33a03eb-9d5a-45d8-87c1-9f537528e0f0', '74c7f263-dafe-4ba8-ac1f-74a5da167637', '1a0cf23b-43da-40f7-a2c3-9a2c22b1aa9f', '54d9e1a1-ff5f-4867-b423-1c3a73a9020d', 'aeb99154-5436-42b1-92e2-33d8de85c797', '5d8928ec-cefa-4480-9bc5-c4e058547020', 'f1fdf06c-8f25-4dd6-b82d-c5486ccc0b5f', '4e6d61e9-bd0d-42ac-b18a-042ff35b20da', '43dc91ce-4a04-4b02-a75f-fc34859de051', 'ee3d0e5a-c846-4623-afbd-24be73182f45', 'a9f6807f-00e0-4444-b86b-0633defef2f4', 'f8fe95d1-2a38-45fe-84a2-3f9c01b6bc21', 'd4897eec-ea3d-4f87-8c36-b1e35f833c91', '371a65a9-da56-45e9-a301-454f643b9436', '426f839e-dd3e-458a-aa0d-a0033284ce9c', '45f8043d-69a1-467b-8fa2-1459e390193f', '6f250972-b02b-4a1f-a577-d41547b10807', '72fa5d4d-d368-44d8-a7d2-f898b27da5d4', '9cbb5e61-abaf-46a1-a52c-660156e7b23e', 'bcd92bab-f502-4812-9c97-db382ca08af2', 'ce0d6601-e048-4b59-b51b-0ce0700ee524', '1964203d-8e39-4b7c-bfc0-569a876e3393', 'c5d86bca-2cb0-432a-8b21-478cad8f5098', 'e494cac4-61c4-4f28-b259-dd8134cc3e43', 'e3eb7a3d-4be2-4d10-9e4b-b3dee1a78b6a', '5de271b7-f271-43ba-bf1e-72b195d8ac0c', '81dac2a4-1a20-4f60-8519-d4c7a827e66c', '8214602b-31dd-4b40-b627-1d4cd4432292', '8fe42656-db5f-46a4-987f-9ce77168a2e4', '31e335a4-4f87-455e-9794-a96e632b050d', '25b7ff78-aeed-4a6e-88cf-2ca0117cbfbd', '3da4b578-a21b-4bde-81ca-10f88d562f70', 'e9c00ec8-6a54-4aff-99a5-7083f8bbc2fc', '6650e86c-aa6f-4761-b09d-8df758b41564', 'ed971cb1-40bb-4cb0-b9dc-9482c24f90db', 'a722e04f-78a9-4bac-bca8-672b099e469a', 'e5ccab4b-5b76-44d0-a55c-e00d435524f4', '44c888ec-b465-491c-8b24-1f7c1fba43bd', 'bec70e60-2c3e-4d91-bc84-4467682bd425', 'fcb148eb-dc08-402d-923b-32eba8218896', '15b8d208-8b77-46ba-9fd6-e9ec80bfe3ca', 'e516c7d1-647e-4b53-9d5f-7abf5dca5ad1', 'b1cc7e63-3448-4ceb-b8a3-f65b8449abc4', 'a1d5d412-f3d5-40f5-87d1-d92f29999073', '41adfa9f-a773-4dd5-a8ef-785a03e791e2', 'b696b84c-9d45-408a-bbda-99325bb4b3c4', '78d14d3f-68e0-4c02-8582-d09f1d792351', '13d601b5-be47-4eb4-8355-27298b1d00eb', '8440a400-1366-4a00-93ac-c1d5b2847e4b', 'f158ee8f-b24b-4bb7-a52b-f908c6233d39', 'c8d8ae4a-ff0c-4a75-9eea-e29b693c52af', '96a36643-43ac-4a1d-b26f-7e91c215a1bd', 'f1dbeecd-811f-48d6-bdf1-5f97ed27d67d', '4d652468-9002-42d1-b7f3-d517238504a9', '6cbc14b3-3ce2-4a61-afbf-6e1cdfe55ad5', 'f2b83c68-2d63-4ae2-8c85-647b4c9dd2df', 'edfb1a81-579c-4eb0-9917-281d1dbf1a4b', '96be1c2c-bbf9-4f35-80aa-56139c4adaae', '216f67f7-fcb1-4729-91d5-e5f999fda1b4', '4a700c78-09fc-482d-86fe-f63ac65fd0f9', '8accf3b1-00bd-42ee-aeb5-3a9cb626408c', '04658e7a-4a3d-4893-acae-fecc332b0b52', '01bcddea-a349-43e1-bcbb-b0abd767ec63', '6de23767-fb03-45e1-b34d-e996ed094b22', 'd2a2d198-b14c-400c-b9ac-369031fb1ac2', '71e5c4d0-c1f8-4625-9884-2eec895c7c0c', '9235a034-c295-4496-aa16-f056e2709c82', 'a3e55fa6-e044-4562-9a3d-6f877bfea944', '36057df9-f1d5-4cef-a053-92ad91f7d3b1', 'afda3a7b-afc0-46f7-96ca-b2bb1157c6d5', '50b99a20-a04e-4fe0-8d31-a4b0ab6f3a17', 'f731dd55-232e-4499-8c12-5f90ada655a2', '46b4ace9-258b-4911-bc2c-96d7f99754be', '0d850789-cec3-4a16-b6b0-d5f9c3701539', '4375221b-143c-483f-848e-b4ee90e0d76a', 'fec670df-9f67-4277-918a-fee2e0fb66ed', 'cb96cfd3-a5db-4197-9989-557422d8e299', '346f866c-b253-4f63-a46a-8b1376cc21e7', '48192109-c998-4aba-aec7-8621cda3ae52', '8b46a357-2aef-45c1-84aa-5a4536ccb0f1', '6b314e2f-f5f1-46fc-8044-478c3e5bbe4a', 'b2b1dfc4-e2c1-4243-911f-435f7ab154be', '0b4d74c2-57fc-4cec-b163-edf4017cb374', 'c2743d9b-0f24-44f7-aa64-669872a97d70', 'da300829-648a-4360-b12d-b103493f0378', '3da8954b-cb4c-4e63-a4db-5fdb431cbdad', '5d59ab1a-0c7b-4aaf-b595-ef0352c5321f', 'fc58409f-43f8-4360-a394-72c934a347f0', '77912bad-c9e6-4533-ab05-e186dc7bc158', 'fade39ae-5ac2-4f9b-90db-1582631fc68f', '71de6b2b-2575-4497-b0a9-3fe9f22acd6d', 'd03b1382-e6ee-473d-99e8-5f64c1ad9ca0', '82bd3cac-2503-4e07-989d-c0b165d2d535', '506f227f-3df1-49a5-915a-784f6bb815e9', '753af009-ccef-4446-9497-f5ef8ca44294', '773728a6-667a-4412-bd64-f23b17edd9a0', 'b7d3438b-a0b4-4219-9b92-bfcecbd37925', '20c17977-a2f9-4ca8-8c89-7621df81cc23', 'aaa9095d-41f4-4261-b04b-82ec3b772739', '695707cd-4d78-4a4d-8ffb-9f7350ff0a09', 'ac112099-6f68-462d-8fa9-22f40b3e223f', '99a74e76-3973-4c4b-bd0d-5dc04511c3d1', '054fb9aa-827b-4ea4-925a-11fc51c02385', 'a12e4e24-62e6-4acd-baff-b99d26b8cbb3', '91e5fadd-8cac-4669-a977-12d6d97db11c', '4304bc08-7013-4c5f-887f-e280877b8802', 'a8cce9e6-aed8-46b4-bf64-a93b249f1fac', 'e7c9192c-fb1f-4c10-9366-0a7f3e2ea385', '8dcae1d7-e302-4c59-8bdb-f9880f3be472', '330dca0c-4faf-44c1-a990-7fcc47e804df', 'f40ad9ac-d6e4-44a6-b6f5-8c6bf95f0a8f', '6300a3a1-9a0d-4512-a84d-05db6afc2754', '60330836-1c58-4cd5-b1c0-64d4905ac01a', 'e14142d4-b18e-4734-887a-b17404f71890', '64e662d4-97f5-4638-b504-13c5390dc83a', 'f5eca602-c479-41e0-ad00-51020daee672', '2ef35c87-570d-42b9-b4b5-b9e36eff9337', 'c2fe57e4-7466-4624-b0de-b6ec63874a9b', '657fda3c-98ea-42d9-828d-b95726bafea5', '9255e71e-ac21-4538-b002-15a5f9fa5732', 'c6f0677c-e8d4-474a-9a06-602df178ddd8', '58a085c4-4f22-4bf4-8be0-95957161e03a', '270fda43-0cc5-48f6-b4b6-149a507a89d5', 'f8f44a11-b3f2-4807-92f3-ef1b40d40b8e', '7f9567eb-b1a4-44e7-8657-00bb4a50a19d', 'fa7a45b6-c07a-4019-8afb-5150682cda22', 'e43f330b-92c7-4051-bc4d-c07a068fd904', 'a7ebf2dd-56c2-43df-a922-a8e073844a62', '7724a27a-dfdd-4cec-a9e2-284df57b04a6', 'e14fddfd-c00e-4b70-a757-f1e8f67e293f', '3536cf3f-057d-4061-a0b7-34f4c9674a24', 'f3783eeb-8b59-4b30-be76-2ff2805fe64f', 'e29e9952-a2c8-4dea-849a-fec5cba3a9f4', '85362fdf-a1fa-4c3e-b1a5-fd113450834c', '21b15b14-7a6c-45a2-8c04-3ffdc4fda179', '24f8cbd7-e819-4e98-8474-c81f5ad8b493', 'a4a3217a-4d47-401d-ae3c-6e85e6792393', '7473cbdd-50d6-4887-84cd-066c830dd5f1', '2710fdf4-c528-40ab-b21e-126df62e805d', '056efc50-c639-4e66-93bb-bd5b934bbf48', 'f195a073-d1b9-44b6-a2ca-66b3ed57b59b', '7510fb70-7fb7-424c-ac00-f2e23dbbe3a1', 'e9810951-b5a3-4c15-ba53-ba74fec8c5e9', 'eeeb92eb-f8e4-4718-837e-d8388302f4b6', 'c46a43d3-13a3-4cef-9e59-0ed2c67cefde', 'ae6197fc-47ce-457a-8fc5-47439cdaa1a5', '86336e95-c206-4534-b170-8316c789427c', '5259176b-123a-417d-8561-8c8b289371dd', 'fd51a003-23f1-474c-a071-a694d53d8d85', '2448ca70-89de-4a9d-9094-c4c3a05ae9b7', '2a3042a4-f520-4a34-acb1-94564d974280', 'cd366cd6-7ad4-4655-9ab6-8a8df8466289', '24e259a0-64ef-4cfb-ad58-37ee78306104', 'f2969cf4-bff5-4f60-8783-e43c4cf2d86b', '40fd776a-4878-4179-a56f-22fd9f93319a', '65204a19-6db8-48fe-a2b7-774ddad01760', '4a28ea1d-bb31-462a-8199-be0baea853cc', '8ef26f25-8c4f-40ef-8f12-2fcf8c0aa94f', '277cf28f-a452-47c8-b4ee-9967c4ac28e7', 'd1fe2ba1-6421-4e9c-848d-248cc3fcc4b0', '0cb8672a-4a95-4e73-bfca-c8fefce5b090', 'b5e7b0f7-9699-40c4-8065-08d361b75249', '2a9fd732-02d6-44d9-99f3-46fb38acfa22', '48c4665d-d7ea-4d41-9465-619cf2ac291d', 'fcff1d08-2668-4c26-a240-62a3713d3dec', '4b373c85-35e4-4d09-929e-16ba133f25e3', 'fbcea041-1ef6-4a4f-84a2-36e9057afcd9', '7bd20b6f-577e-48f5-9571-7da1bfef10d1', 'a0eabf41-4cc0-4365-bc6e-cc272d69c258', 'c530b53e-a3c5-4400-812d-bdd42ba17566', 'c5c31af0-eb73-43c0-9f47-1d0aa34ee604', '15a08eb5-ef45-47db-923c-ae34a50a20a6', '00277320-0731-42e3-8502-aeae543e96d0', '7e06febc-543d-4c0a-8e3b-c8c7aa4a640c', '71d15be2-f467-4a6a-96a9-e6096f7ae0fb', '98f0e786-4e69-4be0-9399-f6a8804cbfcb', '0d7839b0-848c-4d29-8773-ea5a0c84f4a6', '54d7de0b-45e8-420e-9bbc-7d21a741a8db', 'f840ede4-af7c-4fd7-bea9-823fd31744a8', '4d27f6cf-b288-4918-9469-d592d275ad59', '1a0bfa70-bd51-4016-8e40-461e0074920e', 'cebb13e0-bd3a-433f-9d5e-63e36a2e27c2', '3c4edf5e-9223-4e24-81a4-46884cd84be6', 'eb6c6554-667d-46f8-afe1-1735b72002bb', 'e81b0885-68da-4ee1-beb5-2de3e53362f8', 'f60ae9c5-e620-493e-9247-e058a73a82f8', 'c7afa872-358a-401c-85b1-be7c744d236c', '0b8d39b6-1fdf-47cd-aa17-ee15fb5ffb58', 'dddda60f-13ee-4f18-914c-fa145267905c', 'c348df02-a146-4d68-8069-9d242395f233'], metadata={'file_path': '../../Data/txt/Pride_Prejudice.txt', 'file_name': 'Pride_Prejudice.txt', 'file_type': 'text/plain', 'file_size': 772450, 'creation_date': '2024-02-08', 'last_modified_date': '2024-02-08', 'last_accessed_date': '2024-02-08'}),\n",
       " 'b8ff2083-7664-4aae-a9e3-55959af12995': RefDocInfo(node_ids=['66994f0e-be5e-4493-8166-772f2217a6f0', '701e49ba-7339-4d2d-97b5-9c4daee41432', '2c648a87-b58a-48c2-977f-7610c7f89303', 'def9a293-fa9a-4ace-8f6a-1f853e2458ec', 'f1fec5a1-bbd4-4316-92e7-06e4b2d54e90', '63d2cec7-4bdc-40d2-a31f-e185a34d924c', 'db0ac735-42e2-44df-aeee-e3671428860f', '06ae7206-7dec-45dc-9b76-b8c9540df1cf', '37b7c37b-c336-436b-ac76-834fcf50d10c', '012a62b9-5f4f-4345-9e7c-187599dc2644', '18cdadb5-53b1-440b-b0eb-4cb520f02572', 'd786beec-6e80-44fc-b67b-483103761daf', '66b60569-f5f1-4ec6-896a-67078a300986', 'cb843279-8847-4d60-a6af-81a29e3ffb05', 'd02da12e-274a-485b-adfb-f9e353b97dbd', '7acd4034-73f6-429e-88e6-e3c371d16c81', 'b5199e19-f1bd-4231-9104-c9b02a1f3385', '71274c7b-6596-46fc-814a-c5c2333eb0da', '3f7adf99-39b9-480d-9626-e0b9f7c907f5', 'bafd2917-5a7a-45f1-87f9-8ed91b40769a', 'f9dd892e-75d0-4e7b-9815-2fc3429a672f', '7c527b5b-b924-4786-a326-13cd8926f2a2', '1d78fe8f-82d2-4d72-b0c3-4bd008395758', '060c6cd1-72fb-4aff-8bcb-08b46e0855cd', 'e18c1e45-72eb-44c0-8f70-6e919a6a952a', '947fcfd5-7709-4810-a8ac-ad8bdc157544', 'a575c734-2f56-41e6-9b82-74a685508e47', '06e7b706-9cd8-4822-a3af-f2cc7df0e1fe', '0f959499-31d1-4190-b601-8ab42630e69d', '7f86ff51-233a-40c3-b939-7f3404ea9e8a', 'a9cc96ba-6be2-4f7f-bd7e-43721a54444b', 'ea82a900-0c15-4082-b7f8-40187c23c61e', 'a2aefe7c-e936-4129-bd21-813bcff695c9', 'c7ea7447-3165-467b-a05b-3dfbe4ae43cb', '77db04a2-0134-4cef-b164-68cac4038f3c', '7b6713a5-340c-45b2-a3ce-494d450f9216', 'c91a6ab0-76d8-4a6e-9cb2-f588e50858b2', '7b0dd824-5f28-474c-82ff-f5ace15247a2', 'cf792aa6-f2a4-4250-90db-a8ac1eac9aae', 'bb087893-9bbb-495c-a1c3-53d333202a59', '419f8e3a-d904-4055-8697-76e4ed5cfea3', '7b7a0738-ffe3-445d-9563-11d975810355', 'eee5e472-8a27-46c4-b483-2202722b494c', '3d3a8bac-3f05-4f50-a9a3-1179e0dece5f', 'e46a181b-191b-4695-bea3-dbbb18279a53', '561981e6-286d-41b1-b035-ec1fc725b76d', '99cbfc6f-5941-4973-bdce-1168451e7a87', 'dca22e24-1f10-4df2-95da-79dac833b507', 'bf715df1-e806-47af-9855-a5ea6964a84a', '5d1b3361-663c-4e04-a24f-731babcf70a9', '87e2ee19-13e7-478d-9387-6bbb5079c0ce', 'e9e36bca-4562-407e-93dc-65e54e994ee5', 'f80be859-40df-4ff5-9084-765fcfdb75ca', 'bac545a6-58e5-4631-bd18-1625dedd9c0a', 'bb8ebc21-1ae6-4009-878f-38c14dcfa6f6'], metadata={'file_path': '../../Data/txt/RomeoJuliet.txt', 'file_name': 'RomeoJuliet.txt', 'file_type': 'text/plain', 'file_size': 169486, 'creation_date': '2024-02-08', 'last_modified_date': '2024-02-08', 'last_accessed_date': '2024-02-08'})}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ref_doc_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a128e44-0cb8-45ea-8719-afa61176cd12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Querying your data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17998cb2-db67-478c-9078-2f9d6f3a1e7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(retriever_mode=\"embedding\", response_mode=\"accumulate\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2addd392-d887-4a92-a10f-d4e35b2672c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Romeo was a person who had killed Tybalt and was now being advised by Friar Lawrence to go to Mantua until they could find a time to reconcile his friends, beg pardon of the Prince, and call him back with more joy. He was also concerned about Juliet's well-being and wanted to know how she was doing.\n---------------------\nResponse 2: Romeo was a person who came to the same monument where Juliet was buried after hearing the news of her death. He had bought poison from a poor apothecary and came to the vault to die with Juliet.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who was Romeo?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3507e150-ef40-4283-9c08-baef0032ff9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: There is no information provided in the given context about who did the proofreading of Pride and Prejudice.\n---------------------\nResponse 2: The Online Distributed Proofreading Team at http://www.pgdp.net did the proofreading of Pride and Prejudice.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who did the proofreading of Pride and Prejudice?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd9c532a-f8ae-43ca-bb3d-929c8df0f432",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: The publisher of Pride and Prejudice is George Allen.\n---------------------\nResponse 2: The context information does not provide the name of the publisher of Pride and Prejudice.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who is the publisher of Pride and Prejudice?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd975ab9-b40c-4f0a-b475-b501b928150d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Chat with your Data  \n",
    "\n",
    "[Available Chat Modes](https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/usage_pattern.html)  \n",
    "+ best - Turn the query engine into a tool, for use with a ReAct data agent or an OpenAI data agent, depending on what your LLM supports. OpenAI data agents require gpt-3.5-turbo or gpt-4 as they use the function calling API from OpenAI.\n",
    "+ condense_question - Look at the chat history and re-write the user message to be a query for the index. Return the response after reading the response from the query engine.\n",
    "+ context - Retrieve nodes from the index using every user message. The retrieved text is inserted into the system prompt, so that the chat engine can either respond naturally or use the context from the query engine.\n",
    "+ condense_plus_context - A combination of condense_question and context. Look at the chat history and re-write the user message to be a retrieval query for the index. The retrieved text is inserted into the system prompt, so that the chat engine can either respond naturally or use the context from the query engine.\n",
    "+ simple - A simple chat with the LLM directly, no query engine involved.\n",
    "+ react - Same as best, but forces a ReAct data agent.\n",
    "+ openai - Same as best, but forces an OpenAI data agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cfcddcf-c5d7-479a-bcad-3e4de6e5dd08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(chat_mode=\"condense_question\", verbose=True)\n",
    "chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619ba842-8357-4b98-aa55-bfa726c005fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: Can you tell me what happened to Romeo?\nRomeo bought poison from a poor apothecary and went to the vault to die and lie with Juliet.\nQuerying with: When did Romeo buy poison from a poor apothecary and go to the vault to die and lie with Juliet?\nAccording to the letter that Romeo's man Balthasar brought to the Prince, Romeo bought poison from a poor 'pothecary and went to the vault to die and lie with Juliet. The exact time is not mentioned in the given context.\nQuerying with: What kind of poison did Romeo buy from the poor apothecary before going to the vault to die with Juliet?\nAccording to the provided context, Romeo bought a poison from a poor 'pothecary before going to the vault to die with Juliet. The specific kind of poison is not mentioned.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"What did happen to Romeo?\")\n",
    "print(response)\n",
    "response = chat_engine.chat(\"When was that?\")\n",
    "print(response)\n",
    "response = chat_engine.chat(\"What kind of poison?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c3d6bb1-c153-42de-945e-04144b335598",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using  REPL interface  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2441412-b0fb-4532-9a35-8f5da8ba0e24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\nType \"exit\" to exit.\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Human:  Can you tell me what happened to Romeo?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: What is the update on Romeo's situation?\nAssistant: The given context does not provide information on the current situation of Romeo. The last mention of Romeo is when he buys poison from an apothecary and goes to Juliet's grave to use it. The context then shifts to the aftermath of the tragic events involving Romeo and Juliet.\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Human:  What kind of poison?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: What kind of poison did Romeo buy from the apothecary before going to Juliet's grave?\nAssistant: Romeo bought a poison from a poor 'pothecary before going to the vault to die and lie with Juliet. The type of poison is not specified in the given context information.\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Human:  Who is the publisher of Pride and Prejudice?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: What is the name of the publisher of Pride and Prejudice?\nAssistant: The name of the publisher of Pride and Prejudice is George Allen.\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Human:  exit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_engine.chat_repl()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1-Intro_LLamaIndex",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
