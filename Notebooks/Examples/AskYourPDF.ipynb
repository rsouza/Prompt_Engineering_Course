{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62bf611b-a1ba-4408-ab05-4d1eacaa317d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Ask Questions to your Document\n",
    "\n",
    "In this example we are demonstrating how to ask questions to a PDF file.\n",
    "The PDF file is assumed to have been uploaded to the DBFS via a SFTP connection and stored in your user workspace in some folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cde8151-9a50-4b40-9b1a-cc10b42266ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 1. Step: Set-up a cluster\n",
    "<p>\n",
    "- Go to the menu item Compute<p>\n",
    "- Create a new cluster with the 'Create Compute' button<p>\n",
    "- Choose a use case you access to (cf. Policy)<p>\n",
    "- Choose Multi node<p>\n",
    "- Choose Access mode 'No Isolation shared'<p>\n",
    "- Pick the latest databricks runtime<p>\n",
    "- Choose as worker type: g5.4xlarge with: Min workers:2, Max workers: 8<p>\n",
    "- Choose Driver type: g5.4xlarge<p>\n",
    "- Enable autoscaling<p>\n",
    "- Pick a Terminate time, e.g. 240 min.<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33c9ba68-c155-4738-8f52-826cb6762076",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. Step: Install all libraries\n",
    "<p>\n",
    "<em>Comment: Execution takes about 1,5 minute</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2650501f-5177-4be6-8877-9900f68b23a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting funcy\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/d5/08/c2409cb01d5368dcfedcbaffa7d044cc8957d57a9d0855244a5eb4709d30/funcy-2.0-py2.py3-none-any.whl (30 kB)\nInstalling collected packages: funcy\nSuccessfully installed funcy-2.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nRequirement already satisfied: huggingface_hub in /databricks/python3/lib/python3.10/site-packages (0.14.1)\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.10/site-packages (from huggingface_hub) (22.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /databricks/python3/lib/python3.10/site-packages (from huggingface_hub) (4.4.0)\nRequirement already satisfied: tqdm>=4.42.1 in /databricks/python3/lib/python3.10/site-packages (from huggingface_hub) (4.64.1)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from huggingface_hub) (3.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from huggingface_hub) (6.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from huggingface_hub) (2.28.1)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.10/site-packages (from huggingface_hub) (2022.11.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->huggingface_hub) (2022.12.7)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting InstructorEmbedding\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/6c/fc/64375441f43cc9ddc81f76a1a8f516e6d63f5b6ecb67fffdcddc0445f0d3/InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: InstructorEmbedding\nSuccessfully installed InstructorEmbedding-1.0.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nRequirement already satisfied: langchain in /databricks/python3/lib/python3.10/site-packages (0.0.225)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.23.5)\nRequirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /databricks/python3/lib/python3.10/site-packages (from langchain) (0.5.14)\nRequirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.2.4)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /databricks/python3/lib/python3.10/site-packages (from langchain) (2.8.4)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.10/site-packages (from langchain) (3.8.5)\nRequirement already satisfied: PyYAML>=5.4.1 in /databricks/python3/lib/python3.10/site-packages (from langchain) (6.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.10/site-packages (from langchain) (8.1.0)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchain) (2.28.1)\nRequirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /databricks/python3/lib/python3.10/site-packages (from langchain) (0.0.20)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.4.39)\nRequirement already satisfied: pydantic<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.10.6)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (22.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting chromadb\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/a3/c0/cd6d89d4f66511b902a7e070aa755b8140e05bc8065a03bbffa4f2fb916a/chromadb-0.4.11-py3-none-any.whl (426 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 426.5/426.5 kB 29.1 MB/s eta 0:00:00\nRequirement already satisfied: typer>=0.9.0 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (0.9.0)\nCollecting bcrypt>=4.0.1\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/64/fe/da28a5916128d541da0993328dc5cf4b43dfbf6655f2c7a2abe26ca2dc88/bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 593.7/593.7 kB 51.8 MB/s eta 0:00:00\nRequirement already satisfied: pydantic<2.0,>=1.9 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (1.10.6)\nRequirement already satisfied: uvicorn[standard]>=0.18.3 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (0.23.2)\nCollecting posthog>=2.4.0\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/a7/73/35758818228c70348be4c3c66a76653c62e894e0e3c3461453c5341ca926/posthog-3.0.2-py2.py3-none-any.whl (37 kB)\nCollecting typing-extensions>=4.5.0\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\nCollecting pulsar-client>=3.1.0\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/b7/54/ef01474b40f70f59b459497bdd48a28fc582c0cde1914fa3efa53053a23e/pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 51.8 MB/s eta 0:00:00\nCollecting onnxruntime>=1.14.1\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/26/f5/5f0aaf4cbd0017258619a0bfe117e1263035bd501a480eead0799c140025/onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 78.9 MB/s eta 0:00:00\nCollecting tqdm>=4.65.0\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 11.0 MB/s eta 0:00:00\nCollecting overrides>=7.3.1\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/da/28/3fa6ef8297302fc7b3844980b6c5dbc71cdbd4b61e9b2591234214d5ab39/overrides-7.4.0-py3-none-any.whl (17 kB)\nRequirement already satisfied: importlib-resources in /databricks/python3/lib/python3.10/site-packages (from chromadb) (6.0.1)\nCollecting chroma-hnswlib==0.7.3\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/2f/48/f7609a3cb15a24c5d8ec18911ce10ac94144e9a89584f0a86bf9871b024c/chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 39.9 MB/s eta 0:00:00\nRequirement already satisfied: tokenizers>=0.13.2 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (0.13.3)\nRequirement already satisfied: numpy>=1.22.5 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (1.23.5)\nRequirement already satisfied: requests>=2.28 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (2.28.1)\nRequirement already satisfied: fastapi<0.100.0,>=0.95.2 in /databricks/python3/lib/python3.10/site-packages (from chromadb) (0.98.0)\nCollecting pypika>=0.48.9\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/c7/2c/94ed7b91db81d61d7096ac8f2d325ec562fc75e35f3baea8749c85b28784/PyPika-0.48.9.tar.gz (67 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.3/67.3 kB 9.6 MB/s eta 0:00:00\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /databricks/python3/lib/python3.10/site-packages (from fastapi<0.100.0,>=0.95.2->chromadb) (0.27.0)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (22.0)\nRequirement already satisfied: protobuf in /databricks/python3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.0)\nRequirement already satisfied: flatbuffers in /databricks/python3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\nCollecting coloredlogs\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 6.4 MB/s eta 0:00:00\nRequirement already satisfied: python-dateutil>2.1 in /databricks/python3/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\nCollecting monotonic>=1.5\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nCollecting backoff>=1.10.0\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28->chromadb) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28->chromadb) (2.0.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /databricks/python3/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.0.4)\nRequirement already satisfied: h11>=0.8 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\nRequirement already satisfied: python-dotenv>=0.13 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\nRequirement already satisfied: websockets>=10.4 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\nRequirement already satisfied: httptools>=0.5.0 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\nRequirement already satisfied: watchfiles>=0.13 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\nRequirement already satisfied: anyio<5,>=3.4.0 in /databricks/python3/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.5.0)\nCollecting humanfriendly>=9.1\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 14.3 MB/s eta 0:00:00\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.2.0)\nBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml): started\n  Building wheel for pypika (pyproject.toml): finished with status 'done'\n  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=11edf9687a2e95adb6d44f478aecdc037a4f137c3d5205fb4233fddbb5818a55\n  Stored in directory: /root/.cache/pip/wheels/e3/53/af/68fbdf1da05fae3b46925103503d263fc7d779db3c23c3a417\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, typing-extensions, tqdm, pulsar-client, overrides, humanfriendly, chroma-hnswlib, bcrypt, backoff, posthog, coloredlogs, onnxruntime, chromadb\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.64.1\n    Not uninstalling tqdm at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e\n    Can't uninstall 'tqdm'. No files were found to uninstall.\n  Attempting uninstall: bcrypt\n    Found existing installation: bcrypt 3.2.0\n    Not uninstalling bcrypt at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e\n    Can't uninstall 'bcrypt'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\nSuccessfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.11 coloredlogs-15.0.1 humanfriendly-10.0 monotonic-1.6 onnxruntime-1.16.0 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 tqdm-4.66.1 typing-extensions-4.8.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting openpyxl\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/6a/94/a59521de836ef0da54aaf50da6c4da8fb4072fb3053fa71f052fd9399e7a/openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250.0/250.0 kB 17.1 MB/s eta 0:00:00\nCollecting et-xmlfile\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/96/c2/3dd434b0108730014f1b96fd286040dc3bcb70066346f7e01ec2ac95865f/et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\nInstalling collected packages: et-xmlfile, openpyxl\nSuccessfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting python-docx\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/8b/a0/52729ce4aa026f31b74cc877be1d11e4ddeaa361dc7aebec148171644b33/python-docx-0.8.11.tar.gz (5.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 38.0 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: lxml>=2.3.2 in /databricks/python3/lib/python3.10/site-packages (from python-docx) (4.9.1)\nBuilding wheels for collected packages: python-docx\n  Building wheel for python-docx (setup.py): started\n  Building wheel for python-docx (setup.py): finished with status 'done'\n  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184490 sha256=8e162e5688ba228bb9b82e596db06cb860c33e1ef48e48082573ebed3474c9d6\n  Stored in directory: /root/.cache/pip/wheels/1d/fe/93/3630075d641dea5b6e1dc1c82ee0a8a8833ba7d7ab0fee4204\nSuccessfully built python-docx\nInstalling collected packages: python-docx\nSuccessfully installed python-docx-0.8.11\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nRequirement already satisfied: sentence-transformers in /databricks/python3/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (1.1.1)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (0.14.1)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (1.10.0)\nRequirement already satisfied: torchvision in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (0.15.2+cu118)\nRequirement already satisfied: nltk in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (3.7)\nRequirement already satisfied: torch>=1.6.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (2.0.1+cu118)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (4.31.0)\nRequirement already satisfied: sentencepiece in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2022.11.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.8.4)\nRequirement already satisfied: triton==2.0.0 in /databricks/python3/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\nRequirement already satisfied: lit in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\nRequirement already satisfied: cmake in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.2)\nRequirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.0.4)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nRequirement already satisfied: tiktoken in /databricks/python3/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.10/site-packages (from tiktoken) (2.28.1)\nRequirement already satisfied: regex>=2022.1.18 in /databricks/python3/lib/python3.10/site-packages (from tiktoken) (2022.7.9)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nRequirement already satisfied: torch in /databricks/python3/lib/python3.10/site-packages (2.0.1+cu118)\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e/lib/python3.10/site-packages (from torch) (4.8.0)\nRequirement already satisfied: triton==2.0.0 in /databricks/python3/lib/python3.10/site-packages (from torch) (2.0.0)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch) (2.8.4)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from torch) (3.9.0)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch) (1.11.1)\nRequirement already satisfied: cmake in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.2)\nRequirement already satisfied: lit in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting pypdf\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/92/a1/4af912cb0cbde61dc7ba898c06b145be63e46a23cd3e09f83a179af60705/pypdf-3.16.1-py3-none-any.whl (276 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 276.3/276.3 kB 21.6 MB/s eta 0:00:00\nInstalling collected packages: pypdf\nSuccessfully installed pypdf-3.16.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting xformers\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/c7/b4/9f8bea4204f8482c9c9c64bcf86bd209ccfb2ebdb27e3590ef4c1e87b743/xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl (167.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.0/167.0 MB 8.3 MB/s eta 0:00:00\nRequirement already satisfied: torch==2.0.1 in /databricks/python3/lib/python3.10/site-packages (from xformers) (2.0.1+cu118)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from xformers) (1.23.5)\nRequirement already satisfied: triton==2.0.0 in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->xformers) (2.0.0)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->xformers) (2.8.4)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->xformers) (3.9.0)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->xformers) (3.1.2)\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e/lib/python3.10/site-packages (from torch==2.0.1->xformers) (4.8.0)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch==2.0.1->xformers) (1.11.1)\nRequirement already satisfied: cmake in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->xformers) (3.27.2)\nRequirement already satisfied: lit in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->xformers) (16.0.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch==2.0.1->xformers) (2.1.1)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch==2.0.1->xformers) (1.2.1)\nInstalling collected packages: xformers\nSuccessfully installed xformers-0.0.21\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting langchainhub\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/e9/4c/25e098d3f43a57e3d0936ca09c4ad607fd40ac4b784072ccdbd4dfa55967/langchainhub-0.1.13-py3-none-any.whl (3.4 kB)\nCollecting types-requests<3.0.0.0,>=2.31.0.2\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/06/9b/04bb62f11a6824df5d4568439cf0715118c265d0ffbebeb7cf4b8c9caa15/types_requests-2.31.0.2-py3-none-any.whl (14 kB)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchainhub) (2.28.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2.0.4)\nCollecting types-urllib3\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/11/7b/3fc711b2efea5e85a7a0bbfe269ea944aa767bbba5ec52f9ee45d362ccf3/types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\nInstalling collected packages: types-urllib3, types-requests, langchainhub\nSuccessfully installed langchainhub-0.1.13 types-requests-2.31.0.2 types-urllib3-1.26.25.14\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nCollecting llama-cpp-python\n  Downloading https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/packages/packages/ff/ca/8c45e45abb21069f6274efe3f1cf0aca29a1fd089fec6acf924ee4a67c46/llama_cpp_python-0.2.6.tar.gz (1.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 44.4 MB/s eta 0:00:00\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Installing backend dependencies: started\n  Installing backend dependencies: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: typing-extensions>=4.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e/lib/python3.10/site-packages (from llama-cpp-python) (4.8.0)\nRequirement already satisfied: diskcache>=5.6.1 in /databricks/python3/lib/python3.10/site-packages (from llama-cpp-python) (5.6.1)\nRequirement already satisfied: numpy>=1.20.0 in /databricks/python3/lib/python3.10/site-packages (from llama-cpp-python) (1.23.5)\nBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml): started\n  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.6-cp310-cp310-manylinux_2_35_x86_64.whl size=959961 sha256=3aee0182f606618adfd74c07d5f90f82dbff88da2ee6c65bb96c8d1bbac46f34\n  Stored in directory: /root/.cache/pip/wheels/61/96/d9/6daeeb46d2c1eb76c2bf57819389ced68ab9171e5b8c564f69\nSuccessfully built llama-cpp-python\nInstalling collected packages: llama-cpp-python\nSuccessfully installed llama-cpp-python-0.2.6\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://artifacts.rbi.tech/artifactory/api/pypi/pypi-org-pypi-proxy/simple/\nRequirement already satisfied: accelerate in /databricks/python3/lib/python3.10/site-packages (0.21.0)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from accelerate) (5.9.0)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from accelerate) (22.0)\nRequirement already satisfied: torch>=1.10.0 in /databricks/python3/lib/python3.10/site-packages (from accelerate) (2.0.1+cu118)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.8.4)\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-76ff1143-2529-494e-b055-278ad4cb159e/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\nRequirement already satisfied: triton==2.0.0 in /databricks/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\nRequirement already satisfied: cmake in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\nRequirement already satisfied: lit in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 2. Loading all relevant libraries\n",
    "# -----------------------------------------------\n",
    "%pip install funcy\n",
    "%pip install huggingface_hub\n",
    "%pip install InstructorEmbedding\n",
    "%pip install langchain\n",
    "%pip install chromadb\n",
    "%pip install openpyxl\n",
    "%pip install python-docx\n",
    "%pip install sentence-transformers\n",
    "%pip install tiktoken\n",
    "%pip install torch\n",
    "%pip install pypdf\n",
    "%pip install xformers\n",
    "%pip install langchainhub\n",
    "%pip install llama-cpp-python\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74a154d4-9b64-4931-8d00-2cdf9f72da61",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Step 3: Set-up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcac10f8-6547-4461-b1a5-555254f2c04e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# all the function definitions\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings.huggingface import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from functools import partial\n",
    "from funcy import lmap\n",
    "from typing import Tuple, Callable\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b946bc2-e23c-4fa5-afe7-abad7fcf5bf9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Providing the access token to Azure OpenAI\n",
    "# This only works if you have access to the respective use cases\n",
    "# --------------------------------------------------------------\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(scope=\"llm-usecases\", key=\"AZURE_TOKEN\")\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2022-12-01\"\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_base = \"https://rg-rbi-aa-aitest-semantic-vectordb.openai.azure.com/\"\n",
    "\n",
    "openAI_text_llm = AzureOpenAI(deployment_name=\"model-text-davinci-003\", temperature=0)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Load OpenAI Chat model\n",
    "# -----------------------------------------------------------------\n",
    "version = \"2023-07-01-preview\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(scope=\"llm-usecases\", key=\"AZURE_TOKEN\")\n",
    "os.environ[\"OPENAI_API_VERSION\"] = version\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://rg-rbi-aa-aitest-semantic-vectordb.openai.azure.com/\"\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = version\n",
    "openai.api_base = \"https://rg-rbi-aa-aitest-semantic-vectordb.openai.azure.com/\"\n",
    "\n",
    "openAI_chat_llm = AzureChatOpenAI(deployment_name=\"model-gpt-35-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf17f281-af4a-4109-8e23-3bf05ce850a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Huggingface Token: [REDACTED]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# First Register with your company email to Huggingface (free of charge) https://huggingface.co/\n",
    "# Second you get an access token via the section: user profile/edit profile/Access Token\n",
    "# Third register for Llama2 (https://ai.meta.com/resources/models-and-libraries/llama-downloads/). It is free of charge but does require registration. Make sure that you use the same email address as you used for Huggingface\n",
    "\n",
    "from getpass import getpass\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=getpass(\"Huggingface Token:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acd31cfe-1fb5-4d87-b2b6-bb0cc3aa22c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Step 4 - Load required components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df7ecf67-a299-4a16-9602-d708edaefc15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e2c32ea57048c7a90ea5388af45d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d904381d8d7a455697ae7019077beaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab972c3c38e24a0c8e17512210e5a527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358e8610b9954290a88c901da105a455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3359d759b35342d19f09b4ef2c5f0bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0736a8e2bb641d29bf927bc4ca11b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e042530e24604707ab767c4d8261409c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8adc9117a947b886ef562a78e4c174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e420020ff214cb69d8d4519ebe062a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250b9e9b107f4d6882241e6387ec1386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac4959b3d004a92b23bce5a88fe1bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Initialized and load llama-2-7b-chat-hf\n",
    "# Note: You might also use llama-2-13b-chat-hf, but experiment first with the smaller model\n",
    "# Note: Not recommended! 70b variant does work on a 4xA10G GPU but only in 8bit, which is rather slow.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "#model = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "# Start with the Autotokenizer, but you might also try other tokenizers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "# Start with a rather simple pipeline, and then become more sophisticated\n",
    "llama_chat = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    temperature=0.05,\n",
    "    max_new_tokens=400,\n",
    "    #trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df6a0295-684e-4ac7-8863-d7fd7a441c3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b37432ba10e4a4a9a9b8085810c86b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7f436/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977d7c79c3784d89ad225be1c26b59f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e55b04298943248c8063b7208c503c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb7ef55648345b983ac07511a0968ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af419dbee369456ba7ce1a2ad66d3a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0daf57f436/README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18375efeefe84e3b86412bee89c178ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)af57f436/config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3a02cdd3074659aac678f5ce179c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3908eda286d44dcebb6015a519617e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475c9324491e4df6b30bab4193626457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb6268ba9bf4165a5478d1d7ccc510a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d8421bc243451399a69a09ab34696d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9358cca7b7a4991ac03851eb6eeae59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7f436/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174320c8abb547fca2427f08c1b6f760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34211e9176d74ecab9d179b25d06801f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f57f436/modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\nmax_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------\n",
    "# Load InstructXL embeddings used for OpenAI GPT models\n",
    "# -----------------------------------------------------\n",
    "instruct_embeddings = HuggingFaceInstructEmbeddings(\n",
    "    query_instruction=\"Represent the query for retrieval: \", \n",
    "    model_name=\"hkunlp/instructor-xl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac311333-0029-4385-aca9-aed471b5ebed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Chatting with your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56322b2a-4fbd-44b8-8446-9aaca89ea5fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------\n",
    "# Llama2 Set-up\n",
    "# -----------\n",
    "question_template=\"Please answer the following question as diligently as possible: {question}\"\n",
    "\n",
    "def llama_chat_completion(question: str, pipeline: transformers.Pipeline, **pipeline_kwargs: dict[str, Any]) -> list[str]:\n",
    "    query = question_template.format(question=question)\n",
    "    sequences = pipeline(query, **pipeline_kwargs)\n",
    "    return [s[\"generated_text\"] for s in sequences]\n",
    "\n",
    "\n",
    "llama_chat_completion = partial(llama_chat_completion, \n",
    "    pipeline=llama_chat,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    "    temperature=0.05,\n",
    "    top_k=5,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01137eac-420b-4895-adec-fe1829d387a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: You are a market reasearch anaylsts. Plrase project the consumer price index to the years 2024 and 2025?. \n Answer: \n\n\n\n\n\n\n"
     ]
    }
   ],
   "source": [
    "# Put here your question\n",
    "question =\"You are a market reasearch anaylsts. Plrase project the consumer price index to the years 2024 and 2025?\"\n",
    "\n",
    "# Calculate the answer with Llama2\n",
    "answer = llama_chat_completion(question)[0]\n",
    "print(f\"Question: {question}. \\n Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90558961-3ce9-4fe4-8794-e0345bd177e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: You are a market reasearch anaylsts. Plrase give me the numbers for projecting the consumer price index to the years 2024 and 2025?. \n Answer: I'm sorry, but projecting the Consumer Price Index (CPI) for the years 2024 and 2025 requires a comprehensive analysis of various economic factors, including inflation rates, GDP growth, employment rates, and government policies, among others. As an AI language model, I do not have access to real-time economic data or forecasting tools to provide you with accurate projections. It is recommended to consult with a professional economist or research firm for a more accurate CPI projection.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Chat with GPT 3.5\n",
    "# -------------------------\n",
    "SystemPrompt = \"Please answer the following question as diligently as possible.\"\n",
    "UserPrompt = \"You are a market reasearch anaylsts. Plrase give me the numbers for projecting the consumer price index to the years 2024 and 2025?\"\n",
    "\n",
    "response = openAI_chat_llm([\n",
    "    SystemMessage(content=SystemPrompt),\n",
    "    HumanMessage(content=UserPrompt)\n",
    "])\n",
    "\n",
    "answer = response.content\n",
    "\n",
    "print(f\"Question: {UserPrompt}. \\n Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "931be9b8-8422-4710-bc90-63cd23ead3cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Ask your Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0333f9ea-dc2c-44f5-bd7a-afb67d911c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 400 Characters of the Paper: \nSUP-2016 -0062 RBI Group Risk Manual V16.1  \n \nRaiffeisen Bank International  05.09.2023  1/109 \nGroup IRM/ Integrated Risk Analysis   GENERAL  \n \n \n \n \n \n \n \n \n \nSUPPORTING DOCUMENT  \nRBI GROUP RISK MANUAL  \n– RISK ORIENTED BANK MANAGEMENT  \n \nV16.1  \nSUP-2016 -0062 RBI Group Risk Manual V16.1  \n \nRaiffeisen Bank International  05.09.2023  2/109 \nGroup IRM/ Integrated Risk Analysis   GENERAL  \nTa ...\nLenght of Document: 368985\n# Chunks in Document: 1191\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# GPT 3.5 / Load your PDF to the indicated path and ask questions to it\n",
    "# ------------------------------------------------------------\n",
    "#selected_file_path = \"/Workspace/Users/david.eschwe@rbinternational.com/PDFs/Transformer.pdf\"\n",
    "selected_file_path = \"/Workspace/Users/david.eschwe@rbinternational.com/PDFs/RBI Group Risk Manual.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(selected_file_path)\n",
    "\n",
    "document = loader.load()\n",
    "documents_content = '\\n'.join(page.page_content for page in document)\n",
    "\n",
    "len(documents_content)\n",
    "\n",
    "nb_characters = 400\n",
    "\n",
    "print(f\"First {nb_characters} Characters of the Paper: \\n{documents_content[:nb_characters]} ...\")\n",
    "print(f\"Lenght of Document: {len(documents_content)}\")\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "doc_chunks = text_splitter.split_text(documents_content)\n",
    "\n",
    "print(f\"# Chunks in Document: {len(doc_chunks)}\")\n",
    "\n",
    "vector_db = Chroma.from_texts(doc_chunks, instruct_embeddings)\n",
    "chain = load_qa_chain(openAI_text_llm, chain_type=\"stuff\")\n",
    "\n",
    "def ask(question:str):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    answer = chain.run(input_documents=docs, question=question).strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f7162c2-0a7c-4fb6-9ade-1ce25c5efff3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT3.5 // Question: What is a transformer\n\nAnswer: A transformer is a type of neural network architecture that is used for sequence transduction tasks, such as machine translation. It is called a transformer because it transforms input sequences into output sequences using self-attention mechanisms, rather than relying on recurrent or convolutional neural networks. The Transformer model was proposed in a research paper by Vaswani et al. in 2017 and has since become a widely-used and influential architecture in the field of natural language processing.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is a transformer\"\n",
    "answer = ask(question)\n",
    "\n",
    "print(f\"GPT3.5 // Question: {question}\\n\\nAnswer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2d75b40-4d75-44a7-b516-fb7e9f99b058",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Llama2 / Load your PDF to the indicated path and ask questions to it\n",
    "# ------------------------------------------------------------\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llama_chat)\n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "def query(question, verbose=False):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    return chain.run(input_documents=docs, question=question).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f6ac37-9377-4de5-90d3-3a0f1e62d2bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama2 // Question: What is an LRG?\n\nAnswer: LRG stands for Local and Regional Government.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is an LRG?\"\n",
    "\n",
    "answer = query(question)\n",
    "\n",
    "print(f\"Llama2 // Question: {question}\\n\\nAnswer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb91d3e0-98bf-4b44-a567-b2d66e2a451d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AskYourPDF",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
