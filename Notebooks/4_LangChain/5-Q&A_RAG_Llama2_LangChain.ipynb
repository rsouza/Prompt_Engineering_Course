{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ee606cf-5899-4f59-9063-7491065506ae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Ask Questions to multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7077fcef-c453-4b06-9475-d6ff1b9806a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -qU openai\n",
    "#!pip install -qU langchain \n",
    "#!pip install -qU langchain-openai\n",
    "!pip install -qU langchainhub\n",
    "!pip install -qU tiktoken\n",
    "!pip install -qU funcy\n",
    "!pip install -qU huggingface_hub\n",
    "!pip install -qU InstructorEmbedding\n",
    "!pip install -qU langchain\n",
    "!pip install -qU chromadb\n",
    "!pip install -qU openpyxl\n",
    "!pip install -qU docx2txt\n",
    "!pip install -qU python-docx\n",
    "!pip install -qU sentence-transformers\n",
    "!pip install -qU tiktoken\n",
    "!pip install -qU torch\n",
    "!pip install -qU pypdf\n",
    "!pip install -qU xformers\n",
    "!pip install -qU llama-cpp-python\n",
    "!pip install -qU accelerate\n",
    "#%pip install -qU panel\n",
    "#%pip install -qU streamlit\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56f93a8e-de54-46a2-94bb-ecd6d0208acd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d433b791-926a-4470-842d-96a6b716126e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6523bd5-c8bf-4947-9a5f-3e91dfaca713",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# all the function definitions\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from functools import partial\n",
    "from funcy import lmap\n",
    "from typing import Tuple, Callable\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import openai\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings.huggingface import HuggingFaceInstructEmbeddings\n",
    "#from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.schema import Document as LangchainDocument\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ea841b7-788c-4d5c-bf20-077a568042eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Logging to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c250aeb-136a-414d-9e44-008ed67121d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=getpass(\"Huggingface Token:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "424743ca-279a-4e07-a587-949e98f9d4d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#model = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "#model = \"meta-llama/Llama-2-13b-hf\"\n",
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "#model = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "llama_chat = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    temperature=0.05,\n",
    "    max_new_tokens=1000,\n",
    "    #trust_remote_code=True\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llama_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "934a4a37-0437-492f-a611-c0dfd1063816",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# Load InstructXL embeddings used for OpenAI GPT models\n",
    "# -----------------------------------------------------\n",
    "instruct_embeddings = HuggingFaceInstructEmbeddings(\n",
    "    query_instruction=\"Represent the query for retrieval: \", \n",
    "    model_name=\"hkunlp/instructor-xl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5e1366a-cef5-44c4-9002-2f935e96bf2c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Creating a retrieval pipeline  \n",
    "\n",
    "We can use embeddings and vector stores to send only relevant information to our prompt.  \n",
    "The steps we will need to follow are:\n",
    "\n",
    "+ Split all the documents into small chunks of text\n",
    "+ Pass each chunk of text into an embedding transformer to turn it into an embedding\n",
    "+ Store the embeddings and related pieces of text in a vector store, instead of a list of Langchain document objects\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*FWwgOvUE660a04zoQplS7A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d5de6c9-6481-40f8-86a7-4f43902e481f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Setting up Docs and Vector Database folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e30b52-34f8-4679-86d1-fc570d61d89b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pathdocs = \"/Workspace/ds-academy-embedded-wave-4/ExampleDocs/\"\n",
    "docs = os.listdir(pathdocs)\n",
    "docs = [d for d in docs] # if d.endswith(\".pdf\")]\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79ba957e-a824-4b14-b066-13db78da3c21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating the Document Objects\n",
    "\n",
    "Now we will instantiate the PDF Loader, load one small document and create a list of Langchain documents object  \n",
    "Info about the page splitting [here](https://datascience.stackexchange.com/questions/123076/splitting-documents-with-langchain-when-a-sentence-straddles-the-a-page-break)  \n",
    "You can also define your own document splitter using `pdf_loader.load_and_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "310b47ce-595b-4b17-8249-009b9e2ebc34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for filename in os.listdir(pathdocs):\n",
    "    print(f\"Ingesting document {filename}\")\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = pathdocs + filename\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "    elif filename.endswith('.docx') or filename.endswith('.doc'):\n",
    "        doc_path = pathdocs + filename\n",
    "        loader = Docx2txtLoader(doc_path)\n",
    "        documents.extend(loader.load())\n",
    "    elif filename.endswith('.txt'):\n",
    "        text_path = pathdocs + filename\n",
    "        loader = TextLoader(text_path)\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17e75e54-9ab7-454c-a4e8-b01a53cbe24f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunk_overlap = 200\n",
    "#text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separators=[\" \", \",\", \"\\n\"])\n",
    "\n",
    "chunked_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae14d22f-8bf9-491b-8476-e01d3744fa63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(len(chunked_documents))\n",
    "for d in chunked_documents[200:210]:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b932b9d-6b72-41e4-8263-93c8a5835bd9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A quick example on similarity search using Cosine Distance\n",
    "\n",
    "Naive [Implementation of Cosine Similarity Search](https://github.com/chroma-core/chroma/blob/main/chromadb/utils/distance_functions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dccb26a-0b3a-47ab-b369-fdc967d6fb23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity (vector1: list, vector2: list):\n",
    "    if len(vector1) != len(vector2):\n",
    "        return None\n",
    "    else:\n",
    "        scalar_product = 0\n",
    "        norm1 = 0\n",
    "        norm2 = 0\n",
    "        NORM_EPS = 1e-30\n",
    "        for i in range(0, len(vector1)):\n",
    "            scalar_product += vector1[i]*vector2[i]\n",
    "            norm1 += vector1[i]*vector1[i] \n",
    "            norm2 += vector2[i]*vector2[i]\n",
    "        return 1 - (scalar_product / ((norm1**0.5 + NORM_EPS) * (norm2**0.5 + NORM_EPS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "640aefe4-4ef5-4654-abb8-dd33b8a35b41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "text1 = \"Hello World\"\n",
    "text2 = \"Hello\"\n",
    "\n",
    "a = instruct_embeddings.embed_query(text1)\n",
    "b = instruct_embeddings.embed_query(text2)\n",
    "\n",
    "# 768 dimensions for the embeddings\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a77f3c56-0bdb-42df-9632-4297391df89f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(cosine_similarity(a,b))\n",
    "\n",
    "vectordb_text = Chroma.from_texts(texts=[text1], embedding=instruct_embeddings)\n",
    "response = vectordb_text.similarity_search(text2, 1)\n",
    "#response = vectordb_text.similarity_search_by_vector(b)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3275271-25fb-493a-a1de-6aae85abc21b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating our Vector Database  \n",
    "We are using ChromaDB in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "394b6d43-6894-4115-a63a-831f19e78384",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "persist_directory = '/Workspace/ds-academy-embedded-wave-4/VectorDB2/'\n",
    "vectordb = Chroma.from_documents(documents=chunked_documents, \n",
    "                                 #embedding=instruct_embeddings, \n",
    "                                 embedding_function=instruct_embeddings, \n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19975d13-6861-4c6e-a11c-7172c6fc8369",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Retrieving Documents using Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61e259a2-f3b0-4ecc-a6f1-68f44e58a989",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 8})\n",
    "#retriever = vectordb.as_retriever(search_kwargs={\"k\": 1, \"filter\": {\"page\":10}})\n",
    "\n",
    "print(retriever.search_kwargs)\n",
    "print(retriever.search_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d17427d-cc40-4bff-a9f7-91a15921bdb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What is Delta ?\")\n",
    "for d in docs:\n",
    "    print(d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8691eff4-17d9-4c48-bf3c-536c57d05185",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using an LLM to improve retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5df6694-29ab-4f8b-ac57-2b42d3902fd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9522d333-97f5-4832-8227-3e38dbdbb90e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"Who is Romeo?\"\n",
    "llm_response = qa_chain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7580712-e49e-428a-8f3c-f3374a373f8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#print(llm_response)\n",
    "print(llm_response[\"query\"])\n",
    "print(llm_response[\"result\"])\n",
    "#print(llm_response[\"source_documents\"][0].metadata[\"page\"])\n",
    "print(llm_response[\"source_documents\"][0].metadata[\"source\"])\n",
    "print(llm_response[\"source_documents\"][0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e7a196c-ec35-4441-8186-45fde63f2a53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using a Langchain Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d87c90a2-f719-49e4-922d-20317365dd5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template_string = \"\"\"\n",
    "<<SYS>>\n",
    "You are a helpful, respectful and honest assistant. \n",
    "You are working in a european bank in the area of Data Science Modeling. \n",
    "You shall answer questions on the topic.\n",
    "\n",
    "Always help the user finding the best answers from the provided documentation. \n",
    "\n",
    "If you are unsure about an answer, truthfully say \"I don't know\"\n",
    "<</SYS>>\n",
    "\n",
    "[INST] \n",
    "Remember you are an assistant  \n",
    "\n",
    "User: {question}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61b12294-3a38-4dd0-9f56-31da260c68de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"Why any analytical model will degrade over time, according to the AA Models Monitoring Framework?\"\n",
    "#query = \"What are the most recent advances in Natural Language Processing?\"\n",
    "\n",
    "llm_response = qa_chain(prompt_template.format(question=query))\n",
    "print(llm_response['result'])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5-Q&A_RAG_Llama2_LangChain",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
