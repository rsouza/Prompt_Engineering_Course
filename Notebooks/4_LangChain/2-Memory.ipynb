{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a583f8d7-4983-4129-a3c7-62e41ea49d61",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation. At bare minimum, a conversational system should be able to access some window of past messages directly. A more complex system will need to have a world model that it is constantly updating, which allows it to do things like maintain information about entities and their relationships.\n",
    "\n",
    "### Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQcYZAK7bD8PPvjbAIe5tLk19SX9zKaSGHlVrE_vKrDk09tCgj7ujp_re7SpYHI8I7yUA&usqp=CAU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15ddde51-9cdb-41bf-bb78-13dd3567d9fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "565d7a30-79a1-40f2-bbd8-8c8f5195a42e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qU openai\n",
    "!pip install -qU langchain \n",
    "!pip install -qU langchain-openai\n",
    "!pip install -qU tiktoken\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f3bbe6a-64b6-4354-be68-ee57874ea3c7",
     "showTitle": false,
     "title": ""
    },
    "height": 81
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tiktoken\n",
    "\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_openai import AzureOpenAI\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "azure_endpoint = \"https://rg-rbi-aa-aitest-dsacademy.openai.azure.com/\"\n",
    "#azure_endpoint = \"https://chatgpt-summarization.openai.azure.com/\"\n",
    "\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "deployment_name = \"model-gpt-35-turbo\"\n",
    "openai_model_name = \"gpt-35-turbo\"\n",
    "\n",
    "client = AzureOpenAI(api_key=openai.api_key,\n",
    "                     api_version=openai.api_version,\n",
    "                     azure_endpoint=azure_endpoint,\n",
    "                     )\n",
    "\n",
    "chat = AzureChatOpenAI(azure_endpoint=azure_endpoint,\n",
    "                       openai_api_version=openai.api_version,\n",
    "                       deployment_name=deployment_name,\n",
    "                       openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "                       openai_api_type=openai.api_type,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a65b13cc-6d24-4813-8fbe-e6f8024d34f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ConversationBufferMemory  \n",
    "\n",
    "We are going to use the simplest memory type.  \n",
    "Let's check what is happening behind the scenes using the ```verbose``` mode of the LLM:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbeef501-f79b-4daf-8c4e-f84e6c0128f6",
     "showTitle": false,
     "title": ""
    },
    "height": 132
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=chat, memory = memory, verbose=True)\n",
    "conversation.predict(input=\"Hi, my name is Renato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d890d02e-c505-4b39-9033-99f5ff90ad87",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9930d4eb-7330-4274-811e-5c062ef6a8c8",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4ae1d66-dfb5-401b-84ff-667b52b58b37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### As we are using a memory module, we can check what is stored in there:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc403916-dfea-4728-b66a-eda1b14ac3c3",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec308527-fe7b-4ad0-88ff-41ff97c276b3",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f41ce19-0bda-4267-960f-f62db83a1d89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Now let's erase the memory buffer and insert something else in it:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e62ca62a-4812-4d6f-83d8-a9e435c54ff5",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})\n",
    "\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f916a4c1-9a04-45ee-b2ef-6b23d8684962",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d30f3186-cbb5-4ed7-af7a-2a6688ee6c14",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Let's add even more context:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a692de46-13ff-430a-98c7-f832e7f1ef99",
     "showTitle": false,
     "title": ""
    },
    "height": 47
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "066634f3-cb0c-4102-8f95-ba82aff48ee7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Now, let's check if the model still know the information from a previous interaction:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f5cd994-d4f1-49c3-acd2-f39e471eaa82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=chat,\n",
    "                                 memory = memory,\n",
    "                                 verbose=True\n",
    "                                 )\n",
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "534bc8b5-433a-4476-a3ee-a66cda0ed923",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ConversationBufferWindowMemory  \n",
    "\n",
    "We can define a buffer size to determine how much context will be kept:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf576a1d-5b6d-46bb-b6f9-05d6c7ef8853",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e078bbf4-b9e5-42b6-b970-7e8c60b0e3a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### We see that only one interaction was saved. Now let's see how it would be with the LLM:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6f4f0c4-fbb3-4983-9f3e-ab03ae5b039f",
     "showTitle": false,
     "title": ""
    },
    "height": 132
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(llm=chat, memory = memory, verbose=False)\n",
    "conversation.predict(input=\"Hi, my name is Renato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "784f5ca5-c343-4f58-9c21-413095ba833e",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb6b6b71-5700-4d90-ba48-dd78b9fa8a70",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fdf9c65-c96c-4139-8e52-b46855ded00f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ConversationTokenBufferMemory\n",
    "\n",
    "Similarly, we can define a buffer size in the quantity of tokens:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a4a2e17-608f-4d7a-8761-568c928e210b",
     "showTitle": false,
     "title": ""
    },
    "height": 132
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=30)\n",
    "\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Something Beautiful!\"})\n",
    "\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "143f5c8b-28e3-40a1-a78a-241ff1eef074",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ConversationSummaryMemory  \n",
    "\n",
    "This last type of memory creates an automatic summary of the previous interactions to store:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "704981c9-5f30-4bd9-8f26-36d00331e87e",
     "showTitle": false,
     "title": ""
    },
    "height": 285
   },
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=100)\n",
    "\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7f74747-7948-4e96-9f47-2ceba8d34d87",
     "showTitle": false,
     "title": ""
    },
    "height": 98
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=chat, memory = memory, verbose=True)\n",
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50141950-8a4e-453a-80c7-c07a9e369112",
     "showTitle": false,
     "title": ""
    },
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2-Memory",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
